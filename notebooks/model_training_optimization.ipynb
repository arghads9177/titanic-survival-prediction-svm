{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfac77fc-5261-4aff-96eb-51ff58135ed5",
   "metadata": {},
   "source": [
    "# Titanic Passenger Survival Prediction\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This project focuses on predicting whether a passenger survived the sinking of the Titanic based on various features like ticket class, age, gender, and family relations aboard the ship. The dataset provides detailed information about each passenger, enabling the use of classification models to predict survival outcomes. This project demonstrates the use of machine learning classification techniques on one of the most famous datasets in the field of data science.\n",
    "\n",
    "## Source\n",
    "\n",
    "This dataset is vailable on Kaggle in the following link:\n",
    "\n",
    "> https://www.kaggle.com/c/titanic/data\n",
    "\n",
    "## Data Dictionary\n",
    "\n",
    "The dataset contains the following columns:\n",
    "\n",
    "- **survival**: Survival (0 = No, 1 = Yes)\n",
    "- **pclass**: Ticket class (1 = 1st, 2 = 2nd, 3 = 3rd)\n",
    "- **sex**: Gender of the passenger\n",
    "- **age**: Age of the passenger in years\n",
    "- **sibsp**: Number of siblings/spouses aboard the Titanic\n",
    "- **parch**: Number of parents/children aboard the Titanic\n",
    "- **ticket**: Ticket number\n",
    "- **fare**: Passenger fare\n",
    "- **cabin**: Cabin number\n",
    "- **embarked**: Port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)\n",
    "\n",
    "### Variable Notes\n",
    "\n",
    "- **pclass**: A proxy for socio-economic status (SES)\n",
    "  - 1st = Upper class\n",
    "  - 2nd = Middle class\n",
    "  - 3rd = Lower class\n",
    "\n",
    "- **age**: Age is fractional if less than 1. If the age is estimated, it is in the form of `xx.5`.\n",
    "\n",
    "- **sibsp**: Number of siblings/spouses aboard the Titanic.\n",
    "  - Sibling = brother, sister, stepbrother, stepsister\n",
    "  - Spouse = husband, wife (mistresses and fianc√©s were ignored)\n",
    "\n",
    "- **parch**: Number of parents/children aboard the Titanic.\n",
    "  - Parent = mother, father\n",
    "  - Child = daughter, son, stepdaughter, stepson\n",
    "  - Some children traveled only with a nanny, therefore `parch=0` for them.\n",
    "\n",
    "## Objective\n",
    "\n",
    "The goal of this project is to build a classification model that predicts the survival of passengers aboard the Titanic based on the provided features. The project includes data exploration, feature engineering, model building, and evaluation of classification models.\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "- **Model Training**: The objective of model training is to train the model with the dataset so that it can recognise the pattern present in the data so that it can predict the survival of passengers.\n",
    "- **Model Evaluation**: Evaluate the performance of the model with the help of different evaluation metrics such as accuracy, precision, recall and F1 score.\n",
    "- **Model Optimization**: Find the optimal model using cross validation and hyperparameter tuning so that performance of the model is enhanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f237a0f-66c5-4cee-b058-9c6ccb5d5c7c",
   "metadata": {},
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "318caf39-ad5a-4560-a836-23d02a3e134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Model and Evaluation Metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Model Optimization\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9156e81-c839-49ab-a6d0-f0bab3acba46",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e79d9068-b8f7-4e70-8fa7-50f847f43278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Path\n",
    "data_path = \"../data\"\n",
    "model_path = \"../models\"\n",
    "csv_path = os.path.join(data_path, \"titanic_en.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1556f860-afed-4e7d-869e-4d488b73cb62",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "650857b5-4202-4688-be13-2e5c83b5f91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b33da192-6471-4cfb-a3aa-aed164d60ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age  SibSp  Parch     Fare  FamilySize  Sex_male  \\\n",
       "0         0       3  22.0      1      0   7.2500           2         1   \n",
       "1         1       1  38.0      1      0  71.2833           2         0   \n",
       "2         1       3  26.0      0      0   7.9250           1         0   \n",
       "3         1       1  35.0      1      0  53.1000           2         0   \n",
       "4         0       3  35.0      0      0   8.0500           1         1   \n",
       "\n",
       "   Embarked_Q  Embarked_S  \n",
       "0           0           1  \n",
       "1           0           0  \n",
       "2           0           1  \n",
       "3           0           1  \n",
       "4           0           1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7654b9c6-d3b3-4f3e-97d8-eea4f6cf7b21",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff0ea49f-e219-4745-a10c-b70c5138cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the Input and Output Features to use in supervised machine learning model\n",
    "X = df.drop(\"Survived\", axis= 1)\n",
    "y =df[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2d7ce26-d1b1-4ddf-a760-6305ed47c781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Train and Test Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48bf18c4-c17f-48c0-8d32-652df0fb1784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data to convert all the data in same scale\n",
    "\n",
    "# Define scaler\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e006b7ae-495d-4c31-a7ca-5eef05c843a0",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d22d2822-c97a-46ed-9197-894c3a587021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train the model and print the evaluation metrics\n",
    "def train_evaluate(model):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Prediction on train and test data\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Print Evaluation Metrics\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Training Evaluation\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Accuracy: {accuracy_score(y_train, y_train_pred): 0.2f}\")\n",
    "    print(f\"Precision: {precision_score(y_train, y_train_pred):0.2f}\")\n",
    "    print(f\"Recall: {recall_score(y_train, y_train_pred):0.2f}\")\n",
    "    print(f\"F1: {f1_score(y_train, y_train_pred):0.2f}\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Testing Evaluation\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_test_pred): 0.2f}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_test_pred):0.2f}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_test_pred):0.2f}\")\n",
    "    print(f\"F1: {f1_score(y_test, y_test_pred):0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dc71926-c955-4a7d-b1ce-84e1ace2b4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Training Evaluation\n",
      "============================================================\n",
      "Accuracy:  0.68\n",
      "Precision: 0.71\n",
      "Recall: 0.25\n",
      "F1: 0.37\n",
      "============================================================\n",
      "Testing Evaluation\n",
      "============================================================\n",
      "Accuracy:  0.66\n",
      "Precision: 0.76\n",
      "Recall: 0.26\n",
      "F1: 0.38\n"
     ]
    }
   ],
   "source": [
    "# Try with SVM Classifier\n",
    "svc = SVC()\n",
    "train_evaluate(svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7b3a7d-ae7d-4565-8710-a8f7f20acaae",
   "metadata": {},
   "source": [
    "### Insights\n",
    "\n",
    "The similar results between the training and testing sets suggest that the model is not severely overfitting, but the overall low accuracy and F1 score hint at underfitting. The model may not be complex enough to capture the underlying relationships in the data.\n",
    "\n",
    "#### Training Metrics:\n",
    "\n",
    "- **Accuracy (0.68)**: The model correctly classifies **68%** of the training data, which is modest and suggests that the model is not capturing the complexity of the data very well.\n",
    "- **Precision (0.71)**: Precision refers to the percentage of passengers the model predicted as survivors (positive class) who actually survived. With a precision of **0.71 (or 71%)**, the model is reasonably good at identifying true positives, meaning it‚Äôs making relatively few false positive errors.\n",
    "- **Recall (0.25)**: The recall (also known as sensitivity) is quite low at **0.25 (25%)**. This means the model only identifies **25%** of actual survivors, missing **75%** of them (many false negatives). The model is not doing well at finding all the actual survivors.\n",
    "- **F1 Score (0.37)**: The F1 score is the harmonic mean of precision and recall, balancing both metrics. The F1 score of **0.37** suggests that while precision is decent, the poor recall significantly drags down the overall performance.\n",
    "\n",
    "#### Testing Metrics:\n",
    "\n",
    "- **Accuracy (0.66)**: The testing accuracy is **66%**, slightly lower than the training accuracy of **68%**. This suggests that the model's generalization to unseen data is fairly consistent but still not particularly strong.\n",
    "- **Precision (0.76)**: On the test set, the model's precision improves to **0.76**, meaning it is even more confident in the predictions of survivors, with fewer false positives (i.e., non-survivors wrongly predicted as survivors).\n",
    "- **Recall (0.26)**: However, recall remains very low at **26%**, similar to the training recall. The model continues to miss many actual survivors, indicating a large number of false negatives.\n",
    "**F1 Score (0.38)**: The F1 score remains low at **0.38**, similar to the training score, because the recall is poor despite a decent precision.\n",
    "\n",
    "#### Possible Causes of Low Performance:\n",
    "\n",
    "1. **Class Imbalance:**\n",
    "\n",
    "The Titanic dataset typically has an imbalance between survivors and non-survivors, with fewer survivors. This imbalance can affect the SVM classifier‚Äôs ability to learn to correctly identify the minority class (survivors).\n",
    "\n",
    "2. **Model Complexity:**\n",
    "   \n",
    "The SVM model is not tuned(used with default) for this problem. The choice of kernel, regularization parameters, or the lack of feature scaling could be limiting the model's performance. SVMs are sensitive to these aspects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0c5869-0263-4910-975f-a107fb3c638c",
   "metadata": {},
   "source": [
    "### Model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c12447b-ddb3-4288-a5e6-d875eeaaa500",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Function to tune the hyperparameter\n",
    "def tune_hyperparameter(model, param_dict):\n",
    "    # Define GridSearchCV\n",
    "    gscv = GridSearchCV(\n",
    "        model,\n",
    "        param_grid= param_dict,\n",
    "        cv = 5,\n",
    "        verbose= 1\n",
    "    )\n",
    "\n",
    "    # Train model the different hyperparameter\n",
    "    gscv.fit(X, y)\n",
    "\n",
    "    # Print best score\n",
    "    print(f\"Best Score: {gscv.best_score_: 0.2f}\")\n",
    "\n",
    "    # Return best hyperparameter set\n",
    "    best_params = gscv.best_params_\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3a822dc-2016-489f-a522-8d656210ceaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Best Score:  0.79\n",
      "{'C': 0.1, 'gamma': 0.1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter dictionary for SVC\n",
    "param_dict = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'], \n",
    "    'gamma': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# Define SVC\n",
    "svc_ht = SVC()\n",
    "\n",
    "# Hyperpermeter tuning to get best hyperparameters\n",
    "best_params = tune_hyperparameter(svc_ht, param_dict)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43812a6b-4509-433f-bfa9-9e3f3b33cc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Training Evaluation\n",
      "============================================================\n",
      "Accuracy:  0.79\n",
      "Precision: 0.74\n",
      "Recall: 0.68\n",
      "F1: 0.71\n",
      "============================================================\n",
      "Testing Evaluation\n",
      "============================================================\n",
      "Accuracy:  0.78\n",
      "Precision: 0.75\n",
      "Recall: 0.70\n",
      "F1: 0.73\n"
     ]
    }
   ],
   "source": [
    "# Build with best parameter\n",
    "model = SVC(**best_params)\n",
    "train_evaluate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df2024f-6b92-48f2-b168-ec2d24d1b8c1",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "After hyperparameter tuning, the performance of the SVM classifier on the Titanic Survival dataset has improved significantly, with better balance between precision and recall, as well as more consistent performance across training and testing sets. Let's discuss the evaluation metrics,\n",
    "\n",
    "#### Training Metrics:\n",
    "\n",
    "- **Accuracy (0.79)**: The model correctly classifies **79%** of the training data, a considerable improvement from the previous accuracy of **68%**. This suggests the model is learning the patterns in the training data much better after hyperparameter tuning.\n",
    "- **Precision (0.74)**: Precision has slightly decreased from **0.76 to 0.74**. This means that **74%** of passengers the model predicts as survivors are actual survivors. While it's a slight decrease from the previous tuning, it's still reasonable and shows fewer false positives.\n",
    "- **Recall (0.68)**: The recall has increased significantly from **0.25 to 0.68**, meaning the model now correctly identifies **68%** of actual survivors in the training data. This is a big improvement and shows the model is now detecting more true positives and missing fewer actual survivors.\n",
    "- **F1 Score (0.71)**: The F1 score, which balances precision and recall, is now **0.71**, much higher than before (**0.37**). This indicates that the model has a better balance between precision and recall, and is performing well on the training data.\n",
    "\n",
    "#### Testing Metrics:\n",
    "\n",
    "- **Accuracy (0.78)**: The testing accuracy is **78%**, very close to the training accuracy of **79%**. This is a good sign of the model generalizing well to unseen data, with consistent performance on both the training and testing sets.\n",
    "- **Precision (0.75)**: On the test set, precision is **0.75**, which means that **75%** of passengers predicted as survivors are indeed actual survivors. This is a slight improvement from the training precision and suggests that the model is quite reliable in making correct positive predictions.\n",
    "- **Recall (0.70)**: The recall on the test set is **0.70**, meaning the model correctly identifies **70%** of actual survivors in the test data. This is close to the training recall of **0.68**, indicating consistent performance. It shows that the model is now much better at detecting true positives (survivors) compared to the previous results.\n",
    "- **F1 Score (0.73)**: The F1 score on the test set is **0.73**, showing a good balance between precision and recall. The F1 score being close to that of the training data (**0.71**) indicates that the model has improved overall performance.\n",
    "\n",
    "#### Summary\n",
    "\n",
    "1. **Balanced Performance**: The model now has a much better balance between precision and recall, with a high F1 score. This shows that hyperparameter tuning has led to significant improvements in its ability to correctly predict survivors without missing too many or making too many false predictions.\n",
    "2. **Improved Generalization**: The near-equal performance on both training and testing sets suggests that the model is well-optimized and can generalize effectively to unseen data, reducing the risk of overfitting or underfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b689311-a4c4-421f-9060-ab01f0a9ae83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
